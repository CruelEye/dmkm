}
str(car)
View(car)
# melihat korelasi dari tiap variabel, kalau ada korelasi yang tinggi, hilangkan salah satu variabel
pairs.panels(car)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
print(model)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
summary(model)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
print(model)
?print
?print
model
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
model
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
model
# banyaknya pohon yang dibuat dari fungsi default adalah 500, jumlah pohon bisa diganti dari atribut ntree
# banyaknya variabel yang digunakan untuk membuat satu pohon dari fungsi default adalah 2, bisa diganti
# dari atribut mtry. yang mendekati optimal adalah akar dari jumlah atribut.
prediksiRF<-predict(model,testingdat$V7)
confusionMatrix(table(prediksiRF, testingdat$V7))
prediksiRF<-predict(model,testingdat$V7)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
model
# banyaknya pohon yang dibuat dari fungsi default adalah 500, jumlah pohon bisa diganti dari atribut ntree
# banyaknya variabel yang digunakan untuk membuat satu pohon dari fungsi default adalah 2, bisa diganti
# dari atribut mtry. yang mendekati optimal adalah akar dari jumlah atribut.
prediksiRF<-predict(model,testingdat$V7)
testingdat$V1
str(car)
# ubah tipe variabel menjadi tipe faktor
for(i in names(car)){
car[,i]=as.factor(car[,i])
}
str(car)
View(car)
# melihat korelasi dari tiap variabel, kalau ada korelasi yang tinggi, hilangkan salah satu variabel
pairs.panels(car)
model
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
model
# banyaknya pohon yang dibuat dari fungsi default adalah 500, jumlah pohon bisa diganti dari atribut ntree
# banyaknya variabel yang digunakan untuk membuat satu pohon dari fungsi default adalah 2, bisa diganti
# dari atribut mtry. yang mendekati optimal adalah akar dari jumlah atribut.
prediksiRF<-predict(model,testingdat$V7)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(car),replace = T, prob = c(0.8,0.2))
trainingdat<-car[sampel==1, ]
testingdat<-car[sampel==2, ]
#model
set.seed(123)
model<-randomForest(V7~., data=trainingdat)
model
# banyaknya pohon yang dibuat dari fungsi default adalah 500, jumlah pohon bisa diganti dari atribut ntree
# banyaknya variabel yang digunakan untuk membuat satu pohon dari fungsi default adalah 2, bisa diganti
# dari atribut mtry. yang mendekati optimal adalah akar dari jumlah atribut.
prediksiRF<-predict(model,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
# prediksi
prediksiRF<-predict(model,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
plot(prediksiRF)
# prediksi
prediksiRF<-predict(model,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
plot(model)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.05,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.5,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 1,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.25,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.5,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.05,
plot = TRUE,
ntre eTry = 400,
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.05,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.75,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.5,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.75,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.5,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# menyetel tree
setelan<-tuneRF(trainingdat[,-7],
trainingdat[,7],
stepFactor = 0.5,
plot = TRUE,
ntreeTry = 300,
trace = TRUE,
improve = 0.05)
#terlihat dari plot setelan, OOB terendah berada pada mtry=16. artinya ketika kita mengganti banyaknya
# membuat model dengan mtry=16
model16<-randomForest(V7~., data=trainingdat, ntree = 300, mtry = 16, importance = TRUE, proximity = TRUE)
model16
# membuat model dengan mtry=16
model16<-randomForest(V7~., data=trainingdat, ntree = 300, mtry = 16, importance = TRUE, proximity = TRUE)
model16
prediksiRF<-predict(model16,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
# membuat model dengan mtry=16
model16<-randomForest(V7~., data=trainingdat, ntree = 300, mtry = 16, importance = TRUE, proximity = TRUE)
model16
prediksiRF<-predict(model16,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
# terlihat dari model hasil perubahan mtry, akurasi meningkat sebanyak 5%
# membuat model dengan mtry=16
model16<-randomForest(V7~., data=trainingdat, ntree = 300, mtry = 16, importance = TRUE, proximity = TRUE)
model16
prediksiRF<-predict(model16,testingdat)
confusionMatrix(table(prediksiRF, testingdat$V7))
# terlihat dari model hasil perubahan mtry, akurasi model meningkat sebanyak 5%
?tuneRF
?randomForest
knitr::opts_chunk$set(echo = TRUE)
# import library
library(caret)# membangun confusion matriks, melihat akurasi model
# import data, path menyesuaikan
ipeh<- read.csv("../dataset/data_Ipeh.csv", header=T)
View(ipeh)
# melihat struktur data
str(ipeh)
# melihat struktur data
str(ipeh)
#mengubah variabel admit dn rank menjadi bertipe factor
ipeh$admit=as.factor(ipeh$admit)
ipeh$rank=as.factor(ipeh$rank)
pairs.panels(ipeh)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(ipeh),replace = T, prob = c(0.8,0.2))
trainingdat<-ipeh[sampel==1, ]
testingdat<-ipeh[sampel==2, ]
#model
modellogreg<-glm(admit~., data=trainingdat, family = "binomial")
#karena kasus ini hanya admit atau tidak admit, maka model yang dibangun adalah model regresi logistik sederhana.
#jika target class memiliki banyak nilai, gunakan multinomial
summary(modellogreg)
# memecah data menjadi data training(80% dari data awal) dan data test (20% dari data awal)
set.seed(1234)
sampel<-sample(2,nrow(ipeh),replace = T, prob = c(0.8,0.2))
trainingdat<-ipeh[sampel==1, ]
testingdat<-ipeh[sampel==2, ]
#model
modellogreg<-glm(admit~., data=trainingdat, family = "binomial")
#karena kasus ini hanya admit atau tidak admit, maka model yang dibangun adalah model regresi logistik sederhana.
#jika target class memiliki banyak nilai, gunakan multinomial
summary(modellogreg)
coefficients(modellogreg)
#prediksi
prediksilogreg<-predict(modellogreg, testingdat)
confusionMatrix(table(prediksilogreg, testingdat$admit))
prediksilogreg
nrow(prediksilogreg)
prediksilogreg
typeof(prediksilogreg)
#prediksi
prediksilogreg<-predict(modellogreg, testingdat, type="response")
confusionMatrix(table(prediksilogreg, testingdat$admit))
prediksi]
prediksilogreg
#prediksi
prediksilogreg<-predict(modellogreg, testingdat, type="response")
pred<-ifelse(prediksilogreg>0.5, 1, 0)
pred
#prediksi
prediksilogreg<-predict(modellogreg, testingdat, type="response")
pred<-ifelse(prediksilogreg>0.5, 1, 0)
confusionMatrix(table(pred, testingdat$admit))
#prediksi
prediksilogreg<-predict(modellogreg, testingdat)
pred<-ifelse(prediksilogreg>0.5, 1, 0)
confusionMatrix(table(prediksilogreg, testingdat$admit))
#prediksi
prediksilogreg<-predict(modellogreg, testingdat, type="response")#output berupa peluang dari
pred<-ifelse(prediksilogreg>0.5, 1, 0)
confusionMatrix(table(pred, testingdat$admit))
#prediksi
prediksilogreg<-predict(modellogreg, testingdat, type="response")#output berupa peluang dari
prediksilogreg
pred<-ifelse(prediksilogreg>0.5, 1, 0)
confusionMatrix(table(pred, testingdat$admit))
knitr::opts_chunk$set(echo = TRUE)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
View(data)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
View(data)
pairs.panels(data)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
View(data)
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
modelreg<-lm(y~., data=data)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
View(data)
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
# modelreg<-lm(y~., data=data)
# summary(modelreg)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
for(i in names(data)){
data[ ,i]=as.numeric(data[ ,i])
}
str(data)
# modelreg<-lm(y~., data=data)
# summary(modelreg)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
for(i in names(data)){
data[ ,i]=as.numeric(data[ ,i])
}
str(data)
# modelreg<-lm(y~., data=data)
# summary(modelreg)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
for(i in names(data)){
data[ ,i]=as.numeric(data[ ,i])
}
str(data)
modelreg<-lm(y~., data=data)
summary(modelreg)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
for(i in names(data)){
data[ ,i]=as.numeric(data[ ,i])
}
str(data)
modelreg<-lm(y~., data=data)
summary(modelreg)
library(psych)
data<-read.csv("../dataset/anareg.csv", header = TRUE, sep = ";")
pairs.panels(data)
#terlihat dari data bahwa tidak ada korelasi yang berarti antar variabel
#model regresi
str(data)
for(i in names(data)){
data[ ,i]=as.numeric(data[ ,i])
}
str(data)
modelreg<-lm(y~., data=data)
summary(modelreg)
coefficients(modelreg)
knitr::opts_chunk$set(echo = TRUE)
data("iris")
str(iris)
library(tidyverse)# untuk plotting dan mengolah variabel
data("iris")
str(iris)
library(tidyverse)# untuk plotting dan mengolah variabel
#load data
data("iris")
str(iris)
library(tidyverse)# untuk plotting dan mengolah variabel
#load data
data("iris")
str(iris)
iris %>% qplot(Petal.Length, Petal.Width, color = Species)
iris$Petal.Width
library(tidyverse)# untuk plotting dan mengolah variabel
#load data
data("iris")
str(iris)
iris %>% qplot(Petal.Length, Petal.Width, color = Species)
library(tidyverse)# untuk plotting dan mengolah variabel
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species, data=iris)
library(tidyverse)# untuk plotting dan mengolah variabel
library(e1071)
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species, data=iris)
View(modelnaiv)
library(tidyverse)# untuk plotting dan mengolah variabel
library(e1071)#untuk pemodelan SMV
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species)# scatterplot untuk  melihat hubungan panjang, lebar dan warna dari data iris.
library(tidyverse)# untuk plotting dan mengolah variabel
library(e1071)#untuk pemodelan SMV
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species, data=iris)# scatterplot untuk  melihat hubungan panjang, lebar dan warna dari data iris.
#model SVM
modelSVM<-svm(Species~., data=iris)
summary(modelSVM)
plot(modelSVM, data=iris,
Petal.Width~Petal.Length,
slice= list(Sepal.Width = 3,
Sepal.Length = 4))
confusionMatrix(table(pred, iris$Species))
library(tidyverse)# untuk plotting dan mengolah variabel
library(e1071)#untuk pemodelan SMV
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species, data=iris)# scatterplot untuk  melihat hubungan panjang, lebar dan warna dari data iris.
#model SVM
modelSVM<-svm(Species~., data=iris)
summary(modelSVM)
plot(modelSVM, data=iris,
Petal.Width~Petal.Length,
slice= list(Sepal.Width = 3,
Sepal.Length = 4))
pred<-predict(modelSVM, iris)
confusionMatrix(table(pred, ris$Species))
confusionMatrix(table(Predicted = pred, Actual=iris$Species))
plot(modelSVM, data=iris,
Petal.Width~Petal.Length,
slice= list(Sepal.Width = 3,
Sepal.Length = 4))
modelSVM<-svm(Species~., data=iris)
summary(modelSVM)
library(tidyverse)# untuk plotting dan mengolah variabel
library(e1071)#untuk pemodelan SMV
#load data
data("iris")
str(iris)
qplot(Petal.Length, Petal.Width, color = Species, data=iris)# scatterplot untuk  melihat hubungan panjang, lebar dan warna dari data iris.
#model SVM
modelSVM<-svm(Species~., data=iris)
summary(modelSVM)
# Support vector kernel default adalah bertipe radial,
#terdapat beberapa pilihan yaitu sigmoid, polynomial, linear
plot(modelSVM, data=iris,
Petal.Width~Petal.Length,#karena terdapat lebih dari 3 variabel pada dataset ini, perlu didefinisikan variabel mana yang akan ditampilkan, pada kasus ini petal width dan length.
slice= list(Sepal.Width = 3,
Sepal.Length = 4))
pred<-predict(modelSVM, iris)
confusionMatrix(table(Predicted = pred, Actual=iris$Species))
confusionMatrix(table(Predicted = pred, Actual=iris$Species))
summary(modelSVM)
#mencari model terbaik
set.seed(123)
bestmodel<- tune(svm, Species~., data=iris,
ranges = list(epsilon = seq(0,1,0.1),
cost = 2^(2:9)))
#perhatikan nilai cost, jika cost yang ditentukan bernilai besar, bisa terjadi over-fitting, jika terlalu kecil bisa terjadi under-fitting yang berakibat rendahnya akurasi.
plot(bestmodel)
summary(bestmodel)
#mencari model terbaik
set.seed(123)
ngulikngulik<- tune(svm, Species~., data=iris,
ranges = list(epsilon = seq(0,1,0.1),
cost = 2^(2:9)))
#perhatikan nilai cost, jika cost yang ditentukan bernilai besar, bisa terjadi over-fitting, jika terlalu kecil bisa terjadi under-fitting yang berakibat rendahnya akurasi.
plot(nguklikngulik)
plot(ngulikngulik)
summary(ngulikngulik)
bestmodel<-ngulikngulik$best.model
summary(bestmodel)
pred<-predict(bestmodel, iris)
confusionMatrix(table(Predicted = pred, Actual=iris$Species))
pred<-predict(modelSVM, iris)
confusionMatrix(table(Predicted = pred, Actual=iris$Species))
